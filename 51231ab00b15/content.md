%% $ The problem with biased samples %%

Sometimes we use a sample to learn things about a larger population. The hope is that the sample is representative of the population, which means that summary facts about the sample are the same as the corresponding summary facts about the population. If so, then we can use summary facts about the sample to learn things about the population. Because of random fluctuations, we can't be sure that a sample is representative of its population. But there are two things we can do to maximise the likelihood that the sample is representative:

- Choose the sample without bias
- Choose a large enough sample

Here we consider what can happen if you use a biased sampling method. If your selection method is biased, then it might be impossible to get a representative sample, no matter how large the sample is.

# What is a unbiased selection technique?

Choosing the sample without bias means giving everyone in the population an equal chance of being in the sample. If you give some people a higher chance than others, then your sampling method is biased.

Suppose you choose the sample by going to Sydney Airport, and asking people there at random. Then your sampling method is biased, because not everyone in Australia has an equal chance of ending up in the sample. People in the airport at the time have some chance, but no one else has any chance. Even people in the airport might have different chances. If some of them dislike being surveyed, and avoid you, then they too will have no chance of getting into your sample. So your sampling method is biased.

Suppose, instead, that you phone people during the day. Even if you knock on every door in town, this is a biased sampling method. There'll be people who aren't at home, perhaps because they're at work, or away on vacation, and they have no chance of being included in your sample. And people who dislike being surveyed might not answer the door.

A better technique is to get a complete list of everyone in Australia, select randomly from the list, then use whatever technique it takes to find and talk to those people.

# The problem with biased selection

You're effectively choosing from a smaller subset of the population, and that subset might have a different proportion from the population. In extreme cases, it might have a vastly different proportion.

We can illustrate the problem by considering an extreme case. Suppose you're interested in the proportion of Australians in favour of severing ties with the UK and becoming a republic. You have a valid and reliable measurement instrument, one that tells you exactly whether a person is in favour or not. Suppose that the actual proportion of Australians in favour is 50%.

Suppose you select the people by choosing them at random from a pro-republican meeting, all of whom are in favour of becoming a republic. Then no matter how many people you select, your sample proportion will be 100% in favour, which is not the same as the population proportion of 50%. So, no matter how large your sample is, it will not be representative. (Suppose there are thousands at the rally.)

You might get lucky, if the sub-population from which your selecting happens to have the same proportion as the population. If you can be sure this is the case, then perhaps it's fine. But it's very hard to be sure this is the case. You can be sure, though, when you're selecting from the whole population.

# Common sources of sampling bias

**Self-selection bias**. They self-select into the sample. Only unbiased if everyone has an equal desire to be in the sample, which is unlikely. Systematic favoring of certain outcomes that occurs when the individuals who choose participate in a study differ from the individuals who choose to not participate.

You want to find out who's prepared to complete questionairre. So you send out a questionairre, asking whether they're prepared to complete a questionairre.

Example: people respond to a survey - email or phone in. Students and MyExperience.

This includes when we select a sample without bias, but they choose whether to particpate or not, and we ignore the ones who don't and just count the ones who do. We really should count them in the results, even if they don't participate.

Famous case. 1936. Literary Digest. Sample of ten million, subscribers to the Digest, or on the phone. Landslide victory for Landon over Roosevelt. Turned out to be the other way around. What went wrong? Not representative - people who could afford a subscription or a phone were wealthy, which meant mostly Republicans in favour of Landon.

# The moral

If you're working with a sample of data, find out about the selection technique, and check it for bias. It can be difficult to sample without bias, and people often get it wrong.