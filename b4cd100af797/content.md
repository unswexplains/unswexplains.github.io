%% $ The post hoc and cum hoc fallacies %%

We humans have an insatiable appetite for causal explanations. This might have been evolutionarily advantageous, and perhaps it serves us well much of the time. But evolved abilities are typically not perfect (the human visual system can generate illusions, for example), and they're not always in our best interests, especially when they evolved in environments that are different from the one in which we now live (we're afraid of snakes, but not texting while driving, despite the latter being a far greater danger today).

Indeed, our desire for causal explanations often leads us to see causation where it isn't. Sometimes this is harmless, but often it isn't. If we mistakenly think that A causes B, then this can lead to a waste of time and effort. Worse, it can lead us to do harmful things.

There are two fallacies of causal reasoning that we're particularly prone to commit. We're prone to commit them when analysing data, and our audiences are prone to commit them when we're presenting it.

# The post hoc fallacy

Suppose one summer you try a different brand of fertiliser in your garden, and your vegetables grow better than they usually do.

Can you feel the temptation to draw the causal conclusion, that the new fertiliser is to thank?

As tempting as it is, you're not warranted to draw this conclusion. Why not? Granted, it's *possible* that your vegetables grew better than they usually do because of the new fertiliser. But that's unlikely to be the only possible explanation. Perhaps the seedlings you used were a better quality? Perhaps the weather conditions were more favourable? Perhaps there were fewer pests about this summer? There are likely to be many other things that were different in your garden this summer, every one of which provides an alternative possible explanation. As long as there are alternative explanations, you can't conclude that it was due to the new fertiliser. For on what grounds, other than wishful thinking, could you conclude that it was the fertiliser rather than one of the other things?

In fact, it could be even worse - the new fertiliser might actually have had a *deleterious* effect. Perhaps it was worse for your vegetables, but other factors were more significant and your vegetables did better *despite* the new fertiliser. 

To automatically conclude that the new fertiliser is to thank is to commit a fallacy of causal reasoning called the **post hoc** fallacy. The fallacy is to reason as follows:

> A occurred, then B occurred. So, A caused B.

This reasoning is fallacious, because the conclusion does not follow from the premise: just because A occurred and then B occurred, it doesn't *follow* that A caused B. Why the name "post hoc"? It's short for "post hoc ergo propter hoc", which is Latin for "after this therefore because of this", which is how ancient scholars first formulated the reasoning (they wrote in Latin).

We're not always tempted to commit this fallacy. Think about the earthquake that led to the Boxing Day Tsunami of 2004. Just before the earthquake occurred, you did something. Let's say you peeled an apple. So, you peeled an apple, and then the Earthquake occurred. Are you tempted to conclude that your peeling of the apple caused the earthquake? No. You're aware that it cannot possibly have been the cause.

By not drawing this conclusion, in the earthquake case, you're acknowledging that the reasoning is fallacious - that there can be cases in which A happened (you peeled an apple) and then B happened (the earthquake occurred) but A did not cause B.

So why are we ever tempted to reason this way, if we're aware that it's fallacious? It's because of our eagerness to find causal explanations. If we can see a plausible causal mechanism, especially one we would like to be true, we tend to drop our logical guards and jump to that conclusion.

We should never reason this way. If we observe that A happened, and then B happened, we should never thus conclude that A caused B. We can raise the question of whether A caused B - that's fine. But we can't simply conclude that A caused B. To properly draw that conclusion, we need better grounds.

What better grounds are there? How do we properly draw a causal conclusion? It's difficult. We must be able to rule out other possible explanations. That requires knowing what would have happened if A hadn't have occurred, but everything else was the same. What would have happened if you'd used the usual fertiliser, and everything else was the same? Would your vegetables have been worse? The same? Even better? In practice that's difficult to know, if not impossible. We have to approximate it by doing a controlled experiment. And they're difficult to do, and need special training. Here is not the place to explain them.

The point is, if you notice that A happened, and then B happened, don't conclude from that that A caused B. If you want to know whether A caused B, do a controlled experiment. Avoid drawing causal conclusions from your data. You can use the data to raise causal questions, for further investigation. For example, the results in your garden suggest that the new fertiliser might be better than the old. But finding out requires careful investigation - you cannot conclude it from your data.

# The cum hoc fallacy

Suppose you're a university lecturer, and you've noticed a relationship between how often your students attend classes, and how well they perform in exams: the more often they attend classes, the better they perform in exams; the less often they attend classes, the worse they perform in exams.

Can you feel the urge to draw the causal explanation, that going to classes causes them to perform better in exams?

As tempting as it is, you're again not warranted to draw this conclusion. And for the same reason - there are other possible explanations of this relationship.

What other possible explanations are there? Perhaps it's the other way around - performing better in exams causes them to go to classes (by boosting their confidence and interest)? Perhaps neither causes the other - instead, there is some common cause of both, perhaps being interested and conscientious causes both going to classes and performing better in exams? Perhaps there is no causation, it's just a coincidence? (The chance of it being true is small if we have a large sample.)

As long as there are alternative explanations, you can't conclude that it's because going to classes causes better performance. For on what grounds could you conclude that it's this, rather than one of the other things?

To automatically conclude that going to classes causes better performance is to commit a fallacy of causal reasoning called the **cum hoc fallacy**. The fallacy is to reason as follows:

> A and B co-occur. So, A causes B.

Here we're using "A and B co-occur" as a convenient shorthand for "the more A occurs, the more B occurs, and the less A occurs, the less B occurs".  

This reasoning is fallacious, because the conclusion does not follow from the premise: just because A and B co-occur, it doesn't follow that A causes B. Why the name "cum hoc"? It's short for "cum hoc ergo propter hoc", which is Latin for "with this therefore because of this", which is how ancient scholars first formulated the reasoning (in Latin).

We're not always tempted to commit this fallacy. Suppose you learn that, at a certain beach, shark attacks co-occur with ice cream sales. Are you tempted to conclude that shark attacks cause ice cream sales, or that ice cream sales cause shark attacks? Undoubtedly not. By not drawing either of these conclusions you're acknowledging that the reasoning is fallacious - that there can be cases in which A and B co-occur but A does not cause B.

So why are we ever tempted to reason this way, if we're aware that it's fallacious? Again, it's because of our eagerness to find causal explanations. If we can see a plausible causal mechanism, especially one we would like to be true, we tend to drop our logical guards and jump to that conclusion.

We should never reason this way. If we observe that A and B co-occur, we should never thus conclude that A causes B. We can raise the question of whether A causes B - that's fine. But we can't simply conclude that A causes B. To properly draw that conclusion, we again need to do a proper controlled experiment.

[Spurious Correlations](http://tylervigen.com/spurious-correlations)